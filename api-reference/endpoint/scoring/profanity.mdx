---
title: "Profanity Detection"
description: "This method helps safeguard your website or app by detecting offensive or inappropriate language in user inputs. By screening for profanity and other harmful content before itâ€™s made public, you can maintain a positive user environment, protect your brand, and prevent abusive behavior on your platform.\n\nThis method uses Machine Learning (ML) to analyze text and determine whether it contains profanity. It returns a score for the text you pass, classifying it as safe or risky."
api: "GET /scoring/profanity"
---

import { Availability } from "/snippets/Availability.jsx";

### Query Parameters

<ParamField
  query="text"
  type="string"
  placeholder="The text"
  required
>
  The text you want to filter

Sample value: `This is a sample text without profanity!`

</ParamField>

<ParamField
  query="scoreOnly"
  type="string"
  default="no"
  placeholder="The value"
>
  Returns only the score of the text and whether it's safe or not.

Expected values: `yes`, or `no`.

</ParamField>

<ParamField
  query="listBadWords"
  type="string"
  default="no"
  placeholder="The value"
>
  Used to list the bad words in an array.

Expected values: `yes`, or `no`.

</ParamField>

<ParamField
  query="format"
  type="string"
  default="JSON"
  placeholder="Response format"
>
  The format command is used to get a response in a specific format.

Expected values: `JSON`, `XML`, or `CSV`

For more information please refer to [Response Format](/options/response-format).

</ParamField>

<ParamField
  query="mode"
  type="string"
  default="live"
  placeholder="Environment"
>
  The mode command is used to in the development stage to simulate the integration process before releasing it to the production environment.

Expected values: `live`, or `test`.

For more information please refer to [Development Environment](/options/development-environment).

</ParamField>

<ParamField
  query="callback"
  type="string"
  placeholder="JSONP callback"
>
  The callback command can help you make the response as a JSONP format.

Expected values: any name that can be used as a function name in Javascript, e.g: `myFunctionName`.

For more information please refer to [JSONP Callback](/options/jsonp-callback).

</ParamField>

<Panel>
  <Availability plan="Free and above" color="green" />

  <ResponseExample>

```json Success
{
  "data": {
    "isML": true,
    "text": "This is just a normal text",
    "totalBadWords": null,
    "riskScore": 0,
    "isSafe": true,
    "status": "success",
    "executionTime": 120
  }
}
```

```json Error
{
  "status": "error",
  "code": 101,
  "type": "invalid_key",
  "description": "The API Key is missing or invalid."
}
```

  </ResponseExample>
</Panel>

### Response properties

<ResponseField name="data" type="object" required>
  <Expandable title="properties" defaultOpen={true}>
    <ResponseField name="isML" type="boolean" required>
      A boolean value that indicates whether the detection is done by Machine Learning or not.
    </ResponseField>
    <ResponseField name="text" type="string" required>
      The text you passed to the API.
    </ResponseField>
    <ResponseField name="totalBadWords" type="number" required>
      The total number of profane words found in the text.

      **Note:** This field is only available when `isML` is `true`, otherwise you'll get `null`.
    </ResponseField>
    <ResponseField name="riskScore" type="number" required>
      The risk score of the text you passed.
    </ResponseField>
    <ResponseField name="isSafe" type="boolean" required>
      A boolean value that indicates whether the text is safe or not.
    </ResponseField>

  </Expandable>
  <ResponseField name="status" type="string" required>
    The response status.

    Expected values: `success`, or `error`.

  </ResponseField>
  <ResponseField name="executionTime" type="integer" required>
    Time spent in milliseconds to process the data.
  </ResponseField>
</ResponseField>

<Note>
This method returns a score for the text you pass.

We classify profanity into 4 different level. The first level contains the most risky words and phrases (risky). The second level contains the medium-risk words and phrases. Whereas, the third level contains the low-risk words.

When you use the API, the response will the determine the score of the text you passed as follows:

- `riskScore = 0` means that this text is completely safe.
- `riskScode = 1` means that this is a high-risk text.
- `riskScode = 2` means that this is a medium-risk text.
- `riskScode = 3` means that this is a low-risk text.

</Note>
